---
layout: single
title:  "Deep Learning from Scratch_#04"
categories: 
 - Deep Learning_Basic
classes: wide
use_math: true

---

### &lt;밑바닥부터 시작하는 딥러닝&gt; 코드 및 내용을 정리해보았습니다.

 * Deep Learning from Scratch_04

---

## 4. Neural Network Learning

#### _Contents_ 

---
1. 데이터에서 학습한다!
    
    1.1. 데이터 주도 학습<br>
    1.2. 훈련 데이터와 시험 데이터
    
2. 손실 함수
    
    2.1. 오차제곱합<br>
    2.2. 교차 엔트로피 오차<br>
    2.3. 미니배치 학습<br>
    2.4. 교차 엔트로피 오차 구현하기<br>
    2.5. 왜 손실 함수를 설정하는가?

3. 수치 미분

    3.1. 미분<br>
    3.2. 수치 미분의 예<br>
    3.3. 편미분

4. 기울기

    4.1. 경사 하강법<br>
    4.2. 신경망에서의 기울기
    
5. 학습 알고리즘 구현하기

    5.1. 2층 신경망 클래스 구현하기<br>
    5.2. 미니배치 학습 구현하기<br>
    5.3. 시험 데이터로 평가하기

6. 정리  
---

(*말투가 너무 딱딱하게 느껴져 온화하게 바꿔보았습니다..*)

해당 장에선 앞서 fixed variable 이었던 weight $\boldsymbol{W}$를 어떻게 데이터로부터 구하는지 그 과정을 살펴볼 수 있습니다.

결국 weight 최적 값 학습을 loss function의 최소화 문제로 변형하고 최적화 알고리즘을 적용하여 weight를 구한다고 할 수 있는데요, 

이를 위한 최적화 기법이 여럿있겠으나 책에선 잘 알려진 *Gradient Descent Optimization*을 구현하는 것을 소개하여 이를 정리해보았습니다.


```python
%load_ext autoreload
%autoreload 2

from matplotlib.image import imread
from sympy.plotting import plot3d
from PIL import Image

import matplotlib.pyplot as plt
import sympy as sy
import numpy as np
import pickle
import sys
import os
```

    The autoreload extension is already loaded. To reload it, use:
      %reload_ext autoreload


### 1. 데이터에서 학습한다! (PASS)
### 2. 손실함수

신경망은 학습이 잘 됐는지 평가하기 위한 지표(indicator)로써 loss function을 쓰며 그 종류로는 오차제곱합(SSE; Sum of Square for error)과 Cross Entropy 등이 있습니다.

<b>_2.1. 오차제곱합_</b>

$$E = \dfrac{1}{2}\sum_{k}(y_k-t_k)^2$$

$y_k$는 output of neural net, $t_k$는 true label, $k$는 dimension of data에 해당되는데요. 미분이 편하고 차이가 클 수록 값이 커지는 loss 함수입니다.

예를 들어 


```python
y_1 = [0.1, 0.05, 0.6, 0, 0.05, 0.1, 0, 0.1, 0, 0] # softmax 값이므로 확률 값에 해당
y_2 = [0.1, 0.05, 0.1, 0, 0.05, 0.1, 0, 0.6, 0, 0]
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # true label 이므로 one-hot-encoding에 해당

def sum_squares_error(y, t):
    return 0.5 * np.sum((y-t)**2)
```


```python
print('SSE_1 : ',sum_squares_error(np.array(y_1), np.array(t)))
print('SSE_2 : ',sum_squares_error(np.array(y_2), np.array(t)))
```

    SSE_1 :  0.09750000000000003
    SSE_2 :  0.5975


보다시피 정답이 아닌경우 loss 함수의 값이 더 큼을 확인할 수 있습니다.

<b>_2.2. 크로스 엔트로피_</b>

$$E = -\sum_{k}t_k\log y_k$$

Cross Entropy는 SSE와 같이 미분가능하고, 값이 작은 특징이 있습니다.

$t$값이 one-hot value로 주어졌을 땐 다음과 같습니다.

$$E = -\sum_{k}t_k\log y_k$$

정답인 $t=1$이 되고, $-\log y$이 됩니다. 이때 y의 softmax 값이 높아 1에 가까울 수록 오차는 0에 수렴, 아니면 발산하여 오류값이 커지는 형태로 계산됩니다.

$t$ 값이 label value로 주어졌을 때엔, (y는 여전히 one-hot이고  $\therefore t = 1$ )

$$E = -\sum_{k}\log y_k$$

로 생각하면 되니 위의 식과 동일하게 해석할 수 있습니다. 

즉 정답으로 추론한 $y$의 softmax 값이 1 (해당 레이블 확률 100%)에 가까울 수록 엔트로피 $E$ (loss) 값이 0에 수렴하는 셈이 됩니다.


```python
input_x = np.arange(0.1,1.5,0.05)
output_y = np.log(1/input_x)

plt.title('y = log(1/x)')
plt.plot(input_x,output_y)
plt.axhline(0,0,1.5, color='lightgray', linestyle='--')
plt.show()
```


    
![png](/assets/images/DLScratch_04/img_01.png)
    


예를 들어


```python
def cross_entropy_error(y, t):
    delta = 1e-7                # 작은 값을 추가하여 값에 영향은 주지 안되, 발산을 막아 구현 상 overload 방지
    return -np.sum(t * np.log(y + delta))
```


```python
print('CE_1 : ',cross_entropy_error(np.array(y_1), np.array(t)))
print('CE_2 : ',cross_entropy_error(np.array(y_2), np.array(t)))
```

    CE_1 :  0.510825457099338
    CE_2 :  2.302584092994546


해당 케이스 역시 정답과 가까운 1번 케이스의 값이 작은 것을 확인할 수 있습니다.

<b>_2.3. 미니배치 학습_</b>

이전의 Cross Entropy 식을 다량의 데이터에 적용하면 다음과 같습니다.

$$
E = -\dfrac{1}{N}\sum_{n}\sum_{k}t_{nk}y_{nk}
$$

추가된 부분은 데이터의 개수만큼 정규화를 해주는 $\dfrac{1}{N}$부분입니다.

더 나아가, 데이터가 무수히 많아지면 현실적인 문제로 인해 샘플링의 필요성이 커지는데 이를 mini-batch라 하고 코드는 다음과 같습니다.


```python
from mnist import load_mnist

(x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, one_hot_label = True)

print('x_train.shape : ', x_train.shape) # (28*28) 데이터 60000장
print('t_train.shape : ', t_train.shape) # 10개의 label이 존재하는 one-hot 데이터 60000장

train_size = x_train.shape[0]
batch_size = 10
batch_mask = np.random.choice(train_size, batch_size)  # generate random sample from given array
x_batch = x_train[batch_mask]
t_batch = t_train[batch_mask]
print('---------------------------------------')
print('batch_mask : ', batch_mask)
#print('x_batch : ', x_train[batch_mask]) 256개이므로 생략
print('\nt_batch : \n', t_train[batch_mask])
```

    x_train.shape :  (60000, 784)
    t_train.shape :  (60000, 10)
    ---------------------------------------
    batch_mask :  [40250 49018 56428 17728   350 47123  2256 42022 23001 38038]
    
    t_batch : 
     [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
     [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
     [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
     [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
     [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
     [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
     [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
     [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
     [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
     [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]


<b>_2.4. (batch_ver) Cross Entropy 구현하기_</b>

달라진 점은 데이터 $N$ 개에 대한 코드인 점, 그리고 true label 이 one-hot-encoding으로 주어졌는지 only label로 주어졌는지에 따라 두 가지 코드로 나눌 수 있겠습니다.


```python
def cross_entropy_onehot(y, t):
    if y.ndim == 1:                  #true label을 기준으로 차원 변환
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)

    delta = 1e-7
    batch_size = y.shape[0]
    cross_entropy_error = -np.sum(t * np.log(y + delta)) / batch_size #batch size로 나눠주는거 빼곤 다른게 없습니다.
    
    return cross_entropy_error

def cross_entropy_justlabel(y, t):
    if y.ndim == 1:                  #true label을 기준으로 차원 변환
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)

    delta = 1e-7
    batch_size = y.shape[0]
    cross_entropy_error = -np.sum(np.log(y[np.arange(batch_size), t])+ delta) / batch_size 
    
    # y[np.arange(batch_size), t] 정답 인덱스의 y softmax 값을 추출하기 위한 코드. 역시 1과 유사할 수록 cross entropy error가 작아지는 구조다.
    
    return cross_entropy_error
```

<b>_2.5. 왜 손실함수를 설정하는가?_</b>

정확도가 궁극적인 지표가 되지 못하는 이유는 overfitting / 지역최적화라는 말로 설명을 할 수 있을듯 합니다. 이에 알고리즘의 성능을 대변할 수 없습니다. 

우리는 전역최적화를 목표로 삼아야 하고 이는 optimization을 필요로 합니다. 이후 모델의 정확도를 측정하는 것이 순서입니다. 

이에 개별 오차(loss)의 합인 cost function을 정의하고 그 값이 최소화가 되는 지점(미분하여 0이 되는 지점)을 찾아내는 과정을 하는 것입니다. 

### 3. 수치미분

<b>_3.1. 미분_</b>

고등학교 때 배운 미분을 컴퓨터로 구현하기엔 제약사항이 조금 있어 코드를 다듬을 필요가 있습니다.

$$
\dfrac{df(x)}{dx}=\lim_{h\rightarrow0}\dfrac{f(x+h)-f(x)}{h}
$$

실제로 0에 가까운 수를 계산할 수가 없어 어떤 값을 근사치로 이용해야 하느냐란 문제가 생기는데요, 보통 $10^{-4}$ 정도를 쓴다고 알려져있습니다. 당연히 이상치와의 괴리만큼 오차가 생깁니다.

이를 줄이고자 알려져있는 중심 차분을 고려하여 식을 정리하고 구현하면 다음과 같습니다. 

$$
\dfrac{df(x)}{dx}\fallingdotseq\dfrac{f(x+h)-f(x-h)}{2*h} \quad (h = 0.0001)
$$


```python
def numerical_diff(f, x):
    h = 1e-4
    numeric_diff = (f(x+h) - f(x-h))/(2*h)
    return numeric_diff
```

<b>_3.2. 수치미분의 예_</b> : ($y=0.01x^2+0.1x$)   예시에 수치미분을 적용해보겠습니다


```python
def func_1(x):
    return (0.01*x**2 + 0.1*x)

numerical_diff(func_1, 5)
```




    0.1999999999990898



실제 미분 값인 0.2와 근사하게 나옴을 확인할 수 있습니다.

<b>_3.3. 편미분_</b>

$$
f(x_0,x_1) = x_0^2+x_1^2
$$

함수의 모양은 다음과 같으며 미분값 역시 큰 오차가 없습니다.


```python
def func_2(x_1, x_2):
    return (x_1**2 + x_2**2)

x_1 = sy.symbols('x_1')
x_2 = sy.symbols('x_2')

plot3d(func_2(x_1, x_2), (x_1, -2, 2), (x_2, -2, 2), size = (10, 20))
```


    
![png](/assets/images/DLScratch_04/img_02.png)
    





    <sympy.plotting.plot.Plot at 0x1becb861480>



### 4. 기울기

여기서 정의하는 기울기(Gradient)는 모든 변수의 편미분을 벡터로 정리한 것을 의미합니다. 다변수 함수에 이를 구현하여 적용하면 다음과 같습니다.


```python
def numerical_gradient(f, x):
    h = 1e-4                    # 수치미분을 위한 작은 값 h
    grad = np.zeros_like(x)     # x와 shape이 같은 zero-matrix 반환

    for idx in range(x.size):
        tmp_val = x[idx]
        
        #calc f(x+h)
        x[idx] = tmp_val + h
        f_1 = f(x)

        #calc f(x-h)
        x[idx] = tmp_val - h
        f_2 = f(x)

        grad[idx] = (f_1 - f_2)/ (2*h)
        x[idx] = tmp_val        # 값 복원

    return grad    
    
def func_2(x):
    return x[0]**2 + x[1]**2


print(numerical_gradient(func_2, np.array([3.0, 4.0])))
print(numerical_gradient(func_2, np.array([0.0, 2.0])))
print(numerical_gradient(func_2, np.array([3.0, 0.0])))
```

    [6. 8.]
    [0. 4.]
    [6. 0.]


해당 함수의 gradient를 continuous하게 구현하면 다음과 같습니다.


```python
# X의 형태를 matrix로 일반화하여, row와 col을 각각 flatten 하고 gradient를 계산하는 메소드

def gradient_for_anydim(f, X):
    if X.ndim == 1:        # 1차원이므로 row만 flatten
        return numerical_gradient(f, X)
    else:                  # 2차원이므로 col까지 flatten
        grad = np.zeros_like(X)
        
        for idx, x in enumerate(X):
            grad[idx] = numerical_gradient(f, x)
        
        return grad


def function_2_for_anydim(x):
    if x.ndim == 1:
        return np.sum(x**2)
    else:   # col까지 flatten
        return np.sum(x**2, axis=1)

# 범위 설정
x0 = np.arange(-2, 2.5, 0.25)
x1 = np.arange(-2, 2.5, 0.25)
X0, X1 = np.meshgrid(x0, x1)    # 각 범위에 대해 모든 지점을 Grid 형식의 좌표로 반환

X0 = X0.flatten()
X1 = X1.flatten()

# 각 좌표에 대해 grid 별로 gradient 계산
grad = gradient_for_anydim(function_2_for_anydim, np.array([X0, X1]))

plt.figure()
plt.quiver(X0, X1, -grad[0], -grad[1])  # 화살표 플롯 생성
plt.xlim([-2, 2])
plt.ylim([-2, 2])
plt.xlabel('x0')
plt.ylabel('x1')

plt.grid()
plt.show()
```


    
![png](/assets/images/DLScratch_04/img_03.png)
    


화살표의 방향은 3차원 그래프에서 보듯 함수의 지역 최솟값을 가리킵니다. 이는 전역 최솟값이 될 수도 있습니다. 
gradient 기반의 값이기 때문에 output y의 음의 변화폭이 가장 큰 방향을 가리킨다고 해석할 수 있습니다. 

<b>_4.1. 경사하강법_</b>

우리는 손실함수를 정의하고 이를 최소화하는 지점을 전역 최적값(global optimization value)으로 정했습니다.

추가로 이를 찾기 위해 함수의 기울기(gradient)를 미분하는 방법을 이용하기로 하였습니다. 

바로 기울기의 방향으로 일정부분 이동하여 함수 값 및 기울기 변화량을 체크하는 것인데요, 이를 <B>Gradient Descent Method(경사하강법)</B>이라 합니다. 

(일반적으로 손실함수의 최솟값을 찾는다는 의미에 입각하여 '하강법'으로 식을 세팅, 명명하고 있습니다.)

이때 위에서 말한 얼마나 나아가는지를 <B> Learning Rate, 학습률 </B>이라 하고 기호로는 $\boldsymbol \eta$로 표현합니다.

$\eta$ 값은 hyper(user) paramater로써 0.01, 0.001 등의 값을 사용하는데, 너무 크면 최적값을 지나치고 너무 작으면 특정 국소값에 수렴하여 둘 다 문제가 됩니다. 

* 이렇게 찾은 미분 값이 0이 되는 지점은 극솟값, 최솟값, 안장점(saddle point) 혹은 plateau(고원) 등이 있는데 이들은 지역 최적값이지만 전역 최적값을 보장하지는 않는다는 점을 기억해야합니다.

경사하강법을 수식과 코드로 나타내면 다음과 같습니다.

$$
x_0=x_0-\eta\dfrac{\partial f}{\partial x_0}\\ \nonumber
x_1=x_1-\eta\dfrac{\partial f}{\partial x_1}
$$


```python
def gradient_descent(f, init_x, lr = 0.01, step_num = 100):
    x = init_x
    
    for i in range(step_num):
        grad = numerical_gradient(f, x)
        x = x- lr * grad
    return x

init_x = np.array([-3.0, 4.0])
gradient_descent(func_2, init_x = init_x, lr = 0.1, step_num=100)
```




    array([-6.11110793e-10,  8.14814391e-10])



즉 0.1의 학습률로 100번 경사하강을 진행한 후의 x값은 0에 가까운 값에 수렴한다고 해석할 수 있습니다. 이를 plot으로 나타내면 다음과 같습니다.


```python
def gradient_descent_for_plot(f, init_x, lr=0.01, step_num=100):
    x = init_x
    x_history = []              # 점 표기를 위한 리스트

    for i in range(step_num):
        x_history.append( x.copy())
        grad = numerical_gradient(f, x)
        x -= lr * grad

    return np.array(x_history)

x_history = gradient_descent_for_plot(func_2, init_x, lr=0.1, step_num=100)

plt.plot( [-5, 5], [0,0])
plt.plot( [0,0], [-5, 5])
plt.plot(x_history[:,0], x_history[:,1], 'o', markersize = 3 )

plt.xlabel("X0")
plt.ylabel("X1")
plt.show()
```


    
![png](/assets/images/DLScratch_04/img_04.png)
    


<b>_4.2. 신경망에서의 기울기_</b>

이제 신경망에서도 위의 Gradient Descent Method를 적용해보겠습니다.

$$
\begin{align}
\boldsymbol{W}&=
\begin{pmatrix}
w_{11}&w_{12}&w_{13}
\\
w_{21}&w_{22}&w_{23}
\end{pmatrix}\nonumber
\\ \nonumber
\\
\dfrac{\partial L}{\partial \boldsymbol W}&=
\begin{pmatrix}
\dfrac{\partial L}{\partial w_{11}}&
\dfrac{\partial L}{\partial w_{12}}&
\dfrac{\partial L}{\partial w_{13}}
\\\\
\dfrac{\partial L}{\partial w_{21}}&
\dfrac{\partial L}{\partial w_{22}}&
\dfrac{\partial L}{\partial w_{23}}
\end{pmatrix}\nonumber
\end{align}
$$

$\boldsymbol W$는 가중치, $L$은 loss function에 해당되며 이에 대한 gradient 를 위와같이 나타내었습니다.

기존의 코드를 일반화하여 수정하고, 이를 신경망에 적용하여 구현하면 다음과 같습니다.


```python
def softmax(x):
    x = x - np.max(x)           #overflow를 위한 장치

    return np.exp(x) / np.sum(np.exp(x))

def cross_entropy(y, t):
    # 훈련데이터 : one-hot / 정답데이터 : only label 인 경우를 가정한 CEE 계산 코드

    if y.ndim == 1:                  #true label을 기준으로 차원 변환
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)
    
    if t.size == y.size:            # 훈련데이터 : one-hot / 정답데이터 : one-hot인 경우 필요한 변형, 정답인덱스만 추출.
        t = t.argmax(axis=1)

    delta = 1e-7
    batch_size = y.shape[0]
    cross_entropy_error = -np.sum(np.log(y[np.arange(batch_size), t])+ delta) / batch_size 
    
    # y[np.arange(batch_size), t] 정답 인덱스에 해당하는 y softmax 값을 추출하기 위한 코드. 역시 1과 유사할 수록 cross entropy error가 작아지는 구조다.
    
    return cross_entropy_error

def numerical_gradient(f, x):
    h = 1e-4                  # 수치미분을 위한 작은 값 h
    grad = np.zeros_like(x)   # x와 shape이 같은 zero-matrix 변환
    
    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
    # 다차원 배열 x에 대한 객체로, 일반적 접근 방법인 중복 for문을 쓸 필요 없이 스칼라 값에 대한 접근을 가능케 한다.
    # multi_index : 요소 인덱스 값 반환
    # op_flags : operand(피연산자)에 대한 읽고 쓰는 권한 부여

    while not it.finished:
        idx = it.multi_index
        tmp_val = x[idx]
        x[idx] = float(tmp_val) + h
        f_1 = f(x)              # f(x+h)
        
        x[idx] = tmp_val - h 
        f_2 = f(x)              # f(x-h)
        grad[idx] = (f_1 - f_2) / (2 * h)
        
        x[idx] = tmp_val # 값 복원
        it.iternext()           # 다음 요소 접근
        
    return grad
```

Single Layer Perceptron으로 구현하였습니다.


```python
class simpleNet:
    def __init__(self):
        self.W = np.random.randn(2, 3)  # 임의의 정규화된 2x3 weight 배정
    
    def predict(self, x):
        return np.dot(x, self.W)

    def loss(self, x, t):
        z = self.predict(x)
        y = softmax(z)
        loss = cross_entropy(y, t)

        return loss

    def f(self, W):                     # 여기서 W는 dummy variable로, dW 계산 시 인스턴스화 될 때 필요하다. 
        return self.loss(x, t)

    def dW(self):
        return numerical_gradient(self.f, self.W)
```


```python
net = simpleNet()
x = np.array([0.6, 0.9])    # input data x
p = net.predict(x)          # dot product input x & weight w
t = np.array([0, 0, 1])     # true label t

net.dW()

print('1. weight w\n', net.W)                
print('\n2. dot product x & w : ', p)
print('\n3. max z index : ', np.argmax(p)) # t의 레이블과 다르면 CEE 값이 높다.
print('\n4. cross entropy error : ',net.loss(x, t))
print('\n5. Gradient for W\n', net.dW())
```

    1. weight w
     [[ 0.24442401  0.07673328  0.0531962 ]
     [-0.43386236 -0.72365264 -1.19456457]]
    
    2. dot product x & w :  [-0.24382172 -0.60524741 -1.04319039]
    
    3. max z index :  0
    
    4. cross entropy error :  1.5631117172545697
    
    5. Gradient for W
     [[ 0.27955149  0.1947586  -0.47431009]
     [ 0.41932724  0.29213789 -0.71146514]]


Gradient 값은 수치미분 상 작은 값 $h$만큼의 갱신을 위해 필요한 $w$의 값입니다. 손실함수를 최소화하기 위해선 반대 부호로 갱신해야할 것입니다.

주어진 weight 중에선 $w_{23}$이 가장 크게 기여함을 확인할 수 있습니다.

### 5. 학습 알고리즘 구현하기

위의 내용을 요약한 절차는 다음과 같습니다.

* 1단계 : 미니배치 ; 샘플링된 데이터의 손실함수 값을 줄이는 것을 목표로 합니다.
* 2단계 : 기울기 산출 ; 각 weight에 대한 gradient(loss function 값이 작아지는 방향)를 구합니다. 해당 수준은 learning rate($\eta$)로 조절합니다.
* 3단계 : 매개변수 갱신 ; 매개변수를 업데이트를 하며 손실함수의 값 변화를 확인합니다.
* 4단계 : 이를 반복합니다.

전체 모집단이 아닌 표본 집단에 대한 학습이 진행되기 때문에 stochastic 성질을 지닌다하여 

위의 과정을 <b> Stochastic Gradient Descent (SGD) </b> 라고 명명합니다.  

이제 훈련 데이터를 MNIST로 하여 각 과정을 구현해보겠습니다.

<b>_5.1. 2층 신경망 클래스 구현하기_</b>

Two-Layer-Perceptron에 대한 클래스를 구현하면 다음과 같습니다. (_cs231n based_)


```python
def sigmoid(a):
    return 1 / (1 + np.exp(-a))
```


```python
class TwoLayerNet:
    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):
        
    # 가중치 초기화
        self.params = {}
        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)
        self.params['b1'] = np.zeros(hidden_size)
        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)
        self.params['b2'] = np.zeros(output_size)

    def predict(self, x):
        W1 = self.params['W1']
        W2 = self.params['W2']
        b1 = self.params['b1']
        b2 = self.params['b2']

        a1 = np.dot(x, W1) + b1
        z1 = sigmoid(a1)
        a2 = np.dot(z1, W2) + b2
        y = softmax(a2)

        return y

    # t는 just label 형태로 주어집니다.
    def loss(self, x, t):
        y = self.predict(x)

        return cross_entropy(y, t)

    def accuracy(self, x, t):
        y = self.predict(x)
        y = np.argmax(y, axis = 1)
        t = np.argmax(t, axis = 1)

        accuracy = np.sum(y == t) / float(x.shape[0])
        return accuracy

    def numerical_gradient(self, x, t):
        loss_W = lambda W: self.loss(x, t)

        # Cross Entropy Error loss function에 대한 편미분 값 입력.
        grads = {}
        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])
        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])
        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])
        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])

        return grads
    
```

인스턴스화하여 네트워크를 살펴보면 다음과 같습니다.


```python
net = TwoLayerNet(input_size = 784, hidden_size = 100, output_size = 10)

print("net.params['W1'].shape : ",net.params['W1'].shape)
print("net.params['b1'].shape : ",net.params['b1'].shape)
print("net.params['W2'].shape : ",net.params['W2'].shape)
print("net.params['b2'].shape : ",net.params['b2'].shape)
```

    net.params['W1'].shape :  (784, 100)
    net.params['b1'].shape :  (100,)
    net.params['W2'].shape :  (100, 10)
    net.params['b2'].shape :  (10,)


이에대한 랜덤 input data를 이용해 예측을 하면 다음과 같습니다. 

정확도는 훈련이 되지 않아 무의미하기에 구하지 않았습니다.


```python
x = np.random.randn(100, 784)
y = net.predict(x)
t = np.random.randn(100, 10)

net.numerical_gradient(x, t)
```




    {'W1': array([[ 4.12874681e-04,  5.57068969e-05,  4.62698488e-04, ...,
              6.29946184e-05,  1.61149720e-04,  5.08379649e-05],
            [-7.75064768e-05,  3.74171316e-05,  1.98131098e-04, ...,
              3.07118535e-04, -2.76146825e-04, -2.58294990e-04],
            [ 2.47179446e-04,  1.14914935e-04,  1.49155297e-04, ...,
              3.15312221e-05,  8.07427725e-05, -3.63428443e-05],
            ...,
            [-1.33997369e-04,  9.79498793e-05,  2.10508881e-04, ...,
              6.40226250e-04, -3.90395312e-04, -3.05918357e-04],
            [-1.44952561e-04,  1.02376170e-04, -6.92432334e-06, ...,
              7.55235607e-05, -1.48317665e-04, -1.45591477e-04],
            [ 1.22757728e-04,  4.85255036e-05,  3.24943898e-04, ...,
              2.84179977e-04, -1.08030886e-04, -2.38506694e-04]]),
     'b1': array([-2.99671172e-04, -6.90856972e-05,  6.96252611e-05,  6.68210642e-05,
             3.33444579e-04,  4.75449164e-04, -1.81911712e-04, -1.64923977e-04,
            -7.65026664e-05, -1.26409572e-04,  4.44065265e-04,  2.27426611e-04,
             1.50617105e-04,  1.88252560e-04,  1.83247888e-04,  6.03086021e-04,
             2.84454131e-04, -1.65577112e-04, -3.98193722e-04,  3.58017274e-04,
            -5.42290568e-04,  5.01343065e-04, -4.80578288e-05,  3.54211318e-04,
             4.30377018e-04,  4.54712268e-05, -2.32374555e-04, -7.67978654e-04,
             4.99873152e-04, -1.36719409e-04, -2.65819824e-04, -1.83412663e-05,
             ....
             5.30817377e-04,  8.44488262e-04,  4.42761383e-07,  2.07291295e-05,
             7.56670415e-05, -5.70680529e-04, -6.80985268e-05, -2.75923808e-04,
            -1.87628788e-04,  2.42158085e-04,  4.32438609e-04,  5.11840135e-04,
            -5.06859230e-04,  3.56641396e-04,  1.93462371e-04, -6.92913726e-05,
            -5.23986605e-04,  1.44224765e-04,  6.31366839e-04,  4.85449547e-05,
             3.19127875e-04,  5.26282387e-04,  4.47775510e-04,  4.21863180e-04,
            -3.61360675e-05, -1.89516913e-04, -1.64691860e-05,  4.60076306e-04]),
     'W2': array([[-5.78950020e-03,  9.63405728e-03,  1.39081787e-02,
              3.52733198e-02,  2.31399095e-02, -6.22300928e-02,
             -5.40718982e-03, -1.55190877e-02,  1.06279237e-02,
             -3.61871149e-03],
            [-4.94507572e-03,  1.03905826e-02,  1.50818197e-02,
              3.38489818e-02,  2.44296989e-02, -6.20095806e-02,
             -8.05469321e-03, -2.00673638e-02,  1.03990614e-02,
              9.44415728e-04],
            [-6.67566244e-03,  7.71267436e-03,  1.23262185e-02,
              3.59912240e-02,  2.34029121e-02, -5.46502169e-02,
             -6.49307387e-03, -2.01925448e-02,  9.98290234e-03,
             -1.41718725e-03], ...,
     'b2': array([-0.01359648,  0.01625418,  0.0292903 ,  0.07022579,  0.04698035,
            -0.11952166, -0.01323431, -0.03821938,  0.02246084, -0.00063962])}



<b>_5.2. 미니배치 학습 구현하기_</b>

이번엔 input data를 실제 MNIST 데이터 셋으로 불러오고, SGD(Stochastic Gradient Method)를 통해 매개변수 갱신까지 구현해보겠습니다.

매 한 번의 반복마다 100개의 샘플을 추출하고, 학습을 총 1000번 반복하는 셈입니다. 

총 훈련데이터는 10000개에 해당하므로 100번의 반복에 10000개의 데이터가 학습, epoch 1회가 됩니다. 

이 epoch 횟수가 신경망 훈련에서 의미하는 실제 반복횟수입니다. 여기선 총 10회의 epoch을 진행하여 구현하였습니다


```python
from mnist import load_mnist
from tqdm import tqdm # 훈련 시간을 가늠해보기 위한 라이브러리

(x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, one_hot_label = True)

train_loss_list = []

iters_num = 1000
train_size = x_train.shape[0]
batch_size = 100
learning_rate = 0.1

network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)

for i in tqdm(range(iters_num)):        # tqdm으로 반복문을 감싸면 반복횟수별 시간을 통해 loop 종료시간을 유추할 수 있습니다.
    # 미니배치 batch_size만큼 대한 샘플 무작위 추출
    batch_mask = np.random.choice(train_size, batch_size)
    x_batch = x_train[batch_mask]
    t_batch = t_train[batch_mask]

    # 수치미분을 통해 gradient 계산. 추후 backward 계산을 통해 개선하면 훨씬 빠르게 구현할 수 있습니다.
    grad = network.numerical_gradient(x_batch, t_batch)
    
    # 매개변수 갱신
    for key in ('W1', 'b1', 'W2', 'b2'):
        network.params[key] -= learning_rate * grad[key]

    # 반복수에 따른 loss 추이를 위한 경과 기록
    loss = network.loss(x_batch, t_batch)
    train_loss_list.append(loss)   
```

    100%|██████████| 1000/1000 [6:13:54<00:00, 22.43s/it] 



```python
plt.xlabel('iteration')
plt.ylabel('loss')
plt.plot(train_loss_list)
```




    [<matplotlib.lines.Line2D at 0x1becb95b820>]




    
![png](/assets/images/DLScratch_04/img_05.png)
    


반복이 진행될 수록 loss 값이 점점 줄어들고 있음을 확인할 수 있습니다. 

일단 numpy로 진행하기에 병렬계산을 적용할 줄 몰라 시간이 오래걸렸고, 이에 충분한 반복을 수행하지 못했습니다.

실험 조건은 CPU : i5-12600k, RAM : 32GB로, forward 방식으로 진행하다보니 계산이 상당히 더딥니다..

<b>_5.3. 시험 데이터로 평가하기_</b>

위의 데이터를 보면서 내릴 수 있는 결론은 <b>훈련데이터 상에선 학습이 반복될 수록 분별이 잘 된다</b>입니다. 

이것과 시험데이터 상에서도 잘 분류될 것이냐는 다른 문제입니다. 

그 둘의 Gap을 일반화성능 문제라 할 수 있는데요, 이 성능을 체크하기 위해 이번 신경망 훈련의 구현엔

* 미니배치에 대한 iteration_num이 아닌, 전체 데이터를 기준으로 하는 epoch을 기준으로 하였습니다.
* train / test 각각의 정확도 추이를 체크하였습니다.

두 가지를 반영한 결과는 다음과 같습니다.


```python
(x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, one_hot_label = True)

# Hyperparameter
iters_num = 6000
train_size = x_train.shape[0]
batch_size = 100
learning_rate = 0.1

train_loss_list = []
# 정확도 추이
train_acc_list = []
test_acc_list = []

# 60000 / 100 = 600, 즉 600 반복횟수 당 1 epoch에 해당.
iter_per_each = train_size / batch_size 

network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)

for i in tqdm(range(iters_num)):        # tqdm으로 반복문을 감싸면 반복횟수별 시간을 통해 loop 종료시간을 유추할 수 있습니다.
    # 미니배치 batch_size만큼 대한 샘플 무작위 추출
    batch_mask = np.random.choice(train_size, batch_size)
    x_batch = x_train[batch_mask]
    t_batch = t_train[batch_mask]

    # 수치미분을 통해 gradient 계산. 추후 backward 계산을 통해 개선하면 훨씬 빠르게 구현할 수 있습니다.
    grad = network.numerical_gradient(x_batch, t_batch)
    
    # 매개변수 갱신
    for key in ('W1', 'b1', 'W2', 'b2'):
        network.params[key] -= learning_rate * grad[key]

    # 반복수에 따른 loss 추이를 위한 경과 기록
    loss = network.loss(x_batch, t_batch)
    train_loss_list.append(loss)

    #매 600번마다 정확도 추이 계산 (1 epoch 해당))   
    if i % iter_per_each == 0:
        train_acc = network.accuracy(x_train, t_train)
        test_acc = network.accuracy(x_test, t_test)

        train_acc_list.append(train_acc)
        test_acc_list.append(test_acc)
        print("train acc, test acc | "  + str(train_acc) + ", " + str(test_acc))
```

      0%|          | 1/6000 [00:24<40:24:58, 24.25s/it]

    train acc, test acc | 0.09751666666666667, 0.0974


     10%|█         | 601/6000 [4:01:05<34:39:06, 23.11s/it]

    train acc, test acc | 0.81065, 0.8142


     20%|██        | 1201/6000 [7:49:27<30:15:24, 22.70s/it]

    train acc, test acc | 0.8752833333333333, 0.8776


     30%|███       | 1801/6000 [11:37:38<26:30:58, 22.73s/it]

    train acc, test acc | 0.89555, 0.8994


     40%|████      | 2401/6000 [15:25:51<22:44:16, 22.74s/it]

    train acc, test acc | 0.9062, 0.9094


     50%|█████     | 3001/6000 [19:13:15<18:58:17, 22.77s/it]

    train acc, test acc | 0.9136166666666666, 0.9164


     60%|██████    | 3601/6000 [23:02:54<15:48:17, 23.72s/it]

    train acc, test acc | 0.9187666666666666, 0.9208


     70%|███████   | 4201/6000 [26:55:47<11:39:56, 23.34s/it]

    train acc, test acc | 0.9227666666666666, 0.9247


     80%|████████  | 4801/6000 [30:44:41<7:31:42, 22.60s/it] 

    train acc, test acc | 0.9268166666666666, 0.9275


     90%|█████████ | 5401/6000 [34:29:55<3:45:27, 22.58s/it]

    train acc, test acc | 0.9291166666666667, 0.9306


    100%|██████████| 6000/6000 [38:16:15<00:00, 22.96s/it]  



```python
plt.xlabel('epochs')
plt.ylabel('accuracy')

plt.plot(train_acc_list, label='train_acc')
plt.plot(test_acc_list, '--', label = 'test_acc')
plt.legend()

```




    <matplotlib.legend.Legend at 0x1bece461d50>




    
![png](/assets/images/DLScratch_04/img_06.png)
    


위와 같이 epoch이 진행될 수록 훈련/시험 데이터 모두 정확도가 높아짐을 확인할 수 있습니다.

추가로 훈련/시험 데이터의 성능차 또한 적은것으로 미루어 보아  overfitting 없이 좋은 일반화 성능을 갖췄음을 확인할 수 있었습니다.

### 6. 정리하기

* 기계학습에서 사용하는 데이터 셋은 훈련 데이터와 시험 데이터로 나눠 사용합니다.
* 훈련 데이터로 학습한 모델의 범용 능력을 시험 데이터로 평가합니다.
* 신경망 학습은 손실 함수를 지표로, 손실 함수의 값이 작아지는 방향으로 가중치 매개변수를 갱신합니다.
* 가중치 매개변수를 갱신할 때는 가중치 매개변수의 기울기를 이용하고, 기울어진 방향으로 가중치의 값을 갱신하는 작업을 반복합니다.
* 아주 작은 값을 주었을 때의 차분으로 미분하는 것을 수치 미분이라고 합니다.
* 수치 미분을 이용해 가중치 매개변수의 기울기를 구할 수 있습니다.
* 수치 미분을 이용한 계산에는 시간이 걸리지만, 그 구현은 간단하다. 한편, 다음 장에서 구현하는 오차역전파법은 기울기를 고속으로 구현할 수 있습니다.


