## 7. Convoluntional Neural Network

#### _Contents_

---
1. Structure
    
2. Convolutaional Layer
    
    2.1. 완전연결 계층의 문제점<br>
    2.2. 합성곱 연산<br>
    2.3. Padding<br>
    2.4. Stride<br>
    2.5. 3차원 데이터의 합성곱 연산<br>
    2.6. 블록으로 생각하기<br>
    2.7. 배치 처리<br>

3. Pooling Layer

    3.1. 풀링 계층의 특징

4. Implement Convolutional / Pooling Layer

    4.1. 4차원 배열<br>
    4.2. im2row로 데이터 전개하기<br>
    4.3. 합성곱 계층 구현하기<br>
    4.4. 풀링 계층 구현하기<br>
    
5. Implement CNN

6. Visualize CNN

    6.1. 1번째 층의 가중치 시각화하기<br>
    6.2. 층 깊이에 따른 추출 정보 변화

7. Well-Known CNN

    7.1. LeNet<br>
    7.2. AlexNet

8. Overview


---


```python
from matplotlib.image import imread
from sympy.plotting import plot3d
from collections import OrderedDict
from mnist import load_mnist
from PIL import Image
from tqdm import tqdm


import matplotlib.pyplot as plt
import sympy as sy
import numpy as np
import os, sys
import pickle
```

이번 게시글에선 Pooling 계층 구현부터 이어 작성하도록 하겠습니다. 


```python
img_01 = Image.open('./dataset/images/fig 7-1.png')
img_01
```




    
![png](output_3_0.png)
    



현재까지 봤던 신경망은 모든 뉴런끼리 연결되어 있었습니다. 이를 <b>_Fully Connected Layer_</b>라고 합니다. 기존의 fully connected layer는 <b>_affine layer_</b>로 표현하였습니다. 이후 activation function과 연결되고, 해당 구조가 반복되다가 최종 layer에선 softmax로 연결되는 구조였습니다. 

CNN 구조는 다음과 같습니다.


```python
img_02 = Image.open('./dataset/images/fig 7-2.png')
img_02
```




    
![png](output_5_0.png)
    




```python
class Pooling:
    def __init__(self, pool_h, pool_w, stride=1, pad=0):
        self.pool_h = pool_h
        self.pool_w = pool_w
        self.stride = stride
        self.pad = pad
        
        self.x = None
        self.arg_max = None

    def forward(self, x):
        N, C, H, W = x.shape    # conv 연산 이후이므로 x shape : (N, FN, OH, OW)
        p_out_h = int((H - self.pool_h) / self.stride + 1)
        p_out_w = int((H - self.pool_w) / self.stride + 1)

        row = im2row(x, self.pool_h, self.pool_w, self.stride, self.pad)
        # row 값은 기존 (C, H, W) 값의 나열이 (PH, PW) 가 나열되는 형태로 reshape된다
        # 즉 pooling window 사이즈에 맞춰 Channel이 보존된 image 정보 형태로 나열된다
        row = row.reshape(-1, self.pool_h*self.pool_w)
        arg_max = np.argmax(row, axis=1) # 각 row의 max 값 위치 인덱스 저장
        p_out = np.max(row, axis=1) # 각 row에 대해 max pooling이 이루어진다
        # (N*P_OH*P_OW*C, 1)에 대해서 reshape이 이루어진다 (그냥 쓰면 안 될지 궁금하다)
        p_out = p_out.reshape(N, p_out_h, p_out_w, C).transpose(0, 3, 1, 2)

        self.x = x
        self.arg_max = arg_max
        # out shape : (N, FN, P_OH, P_OW)
        return p_out

    def backward(self, dout):
        # 1. reshape / transpose 역연산 ======================
        # 1.1. transpose
        dout = dout.transpose(0, 2, 3, 1)
        # 1.2. reshape은 flatten되어 있으므로 shape 함수로 대체
        #---------------------------------------------------

        # 2. pooling 역연산 ==================================
        pool_size = self.pool_h * self.pool_w # pooling window 
        dmax = np.zeros((dout.size, pool_size)) # (N*OH*OW*C, PH*PW) 복원
        # dmax에 각 max pooling 된 위치 인덱스를 저장. 아닌 곳은 zero
        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()
        #---------------------------------------------------
        
        # 3. row2im 역연산 ===================================
        # dmax : (N, OH, OW, C, FH*FW)으로 reshape
        dmax = dmax.reshape(dout.shape + (pool_size,))
        # drow : dmax를 통해 (N*OH*OW,C*FH*FW) 형태로 변환, row2im 출력 shape에 해당한다.
        drow = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2],  -1)
        dx = row2im(drow, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)
        #---------------------------------------------------

        return dx
```

### 5. Implement CNN

이번 장에선 새로 구현한 계층 및 그 연산과 함께 MNIST를 인식할 수 있는 CNN을 구현해보겠습니다. 구현할 네트워크는 다음과 같습니다.


```python
im_ratio = 0.9
img_14 = Image.open('./dataset/images/fig 7-23.png')
img_14 = img_14.resize((int(img_14.size[0]*im_ratio),int(img_14.size[1]*im_ratio)))
img_14
```




    
![png](output_8_0.png)
    



해당 구현을 위해 지금까지 구현했던 관련된 코드들을 다음의 순서대로 모아보았습니다.

<b>_1. Layer 구현_</b>

        1.1.Relu class
        1.2. Affine class
        
            1.3.1. softmax function
            1.3.2. cross_entropy function
        1.3. SoftmaxWithLoss class
    
<b>_2. Optimization 구현_</b>
   
        2.1. SGD class
        2.2. Momentum class
        2.3. AdaGrad class
        2.4. Adam class

<b>_3. Train 구현_</b>
        
        3.1. Trainer class


```python
#-----------------------------------------------------------------------
# 1.1. Relu class
########################################################################
class Relu:
    def __init__(self):
        self.mask = None            # mask는 T/F로 구성된 넘파이 배열로, 범위에 따른 T/F를 반환합니다.
    
    def forward(self, x):
        self.mask = (x <= 0)        # 0 이하면 True 반환, out value 0 반환
        out = x.copy()
        out[self.mask] = 0 

        return out   

    def backward(self, dout):       # dout 값에 곱해지는 값임을 잊지말 것
        dout[self.mask] = 0         # dout * 0
        dx = dout                   # dout * 1
        
        return dx
#-----------------------------------------------------------------------
# 1.2. Affine class
########################################################################
class Affine:
    def __init__(self, W, b):
        self.W = W
        self.b = b
        self.x = None
        self.original_x_shape = None
        self.dw = None
        self.db = None

    def forward(self, x):
        ###########################################################         
        # tensor 대응
        self.original_x_shape = x.shape # tensor 차원을 튜플형식으로 반환
        x = x.reshape(x.shape[0],-1)    # data input에 맞춰 array 변환
        ###########################################################
        self.x = x

        out = np.dot(self.x, self.W) + self.b
        
        return out

    def backward(self, dout):
        # Batch data shape을 맞추기위한 transpose T
        dx = np.dot(dout, self.W.T)
        self.dW = np.dot(self.x.T, dout)
        self.db = np.sum(dout, axis = 0)

        dx = dx.reshape(*self.original_x_shape) 
        # 여기서 star(*)는 컨테이너 타입의 데이터를 unpacking하기 위한 목적이다. 텐서의 경우 가변인자가 되므로 사용한 것으로 추측.
        return dx
#-----------------------------------------------------------------------
# 1.3.1. softmax functioin
########################################################################
def softmax(x):
    # batch 데이터의 경우 데이터의 갯수와 flatten 된 입력값을 포함하면 (100, 784)와 같은 2차원이되므로 차원을 필수로 고려해야한다.
    # 784 내에서 최대값만 빼야하는데 np.max의 경우 스칼라 최댓값만 고려하므로 axis를 지정해야하고,
    # batch 개수만큼 최댓값을 빼줘야하는데 이를 위해선 transpose가 필요하다. 이를 위해 불필요해보이는 두 번의 transpose가 수행되는 것
    if x.ndim == 2:                 # 기존 X : (N, x) 가정
        x = x.T                     # new X : (x, N)
        x = x - np.max(x, axis=0)   # np.max(x, axis=0) : (1, N)
                                    # (x, N) - (1, N) //차 연산 수행가능, (x', N) 반환
        y = np.exp(x) / np.sum(np.exp(x), axis=0)   # 동일하게 적용, (x'', N) 반환
        return y.T                  # (N, x'') 반환

    x = x - np.max(x)   # exp(x + c')을 통해 resizing을 하여 overflow 문제 해결.
                        # 이때 c'값을 - max(x)를 취하여 지수함수의 발산문제 해결
    return np.exp(x) / np.sum(np.exp(x))
#-----------------------------------------------------------------------
# 1.3.2. cross entropy function
########################################################################
def cross_entropy(y, t):
    # 훈련데이터 : one-hot / 정답데이터 : only label 인 경우를 가정한 CEE 계산 코드
    if y.ndim == 1:                  #true label을 기준으로 차원 변환
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)
    
    if t.size == y.size:            # 훈련데이터 : one-hot / 정답데이터 : one-hot인 경우 필요한 변형, 정답인덱스만 추출.
        t = t.argmax(axis=1)

    delta = 1e-7                    # t = 1일 때 CEE 값인 log(1/y + delta)를 통해 overflow를 방지.
    batch_size = y.shape[0]
    cross_entropy_error = -np.sum(np.log(y[np.arange(batch_size), t]+ delta)) / batch_size 
    # y[np.arange(batch_size), t] 정답 인덱스에 해당하는 y softmax 값을 추출하기 위한 코드. 역시 1과 유사할 수록 cross entropy error가 작아지는 구조다.
    
    return cross_entropy_error
#-----------------------------------------------------------------------
# 1.3. SoftmaxWithLoss class
########################################################################
class SoftmaxWithLoss:
    def __init__(self):
        self.loss = None
        self.y = None
        self.t = None

    def forward(self, x, t):
        self.t = t
        self.y = softmax(x)
        self.loss = cross_entropy(self.y, self.t)

        return self.loss
    
    def backward(self, dout = 1):
        batch_size = self.t.shape[0]

        if self.t.size == self.y.size: # 정답 레이블이 원-핫 인코딩 형태일 때
            dx = (self.y - self.t) / batch_size
        else:                          # 정답 레이블이 단순 레이블인 경우
            dx = self.y.copy()
            dx[np.arange(batch_size), self.t] -= 1
            dx = dx / batch_size
                
        return dx
#-----------------------------------------------------------------------
# 2.1. SGD class
########################################################################
class SGD:
    def __init__(self, lr=0.01):
        self.lr = lr

    def update(self, params, grads):
        for key in params.keys():
            params[key] -= self.lr * grads[key]
#-----------------------------------------------------------------------
# 2.2. Momentum class
########################################################################
class Momentum:
    def __init__(self, lr=0.01, momentum=0.9):
        self.lr = lr
        self.momemtum = momentum
        self.v = None

    def update(self, params, grads):
        if self.v is None:
            self.v = {}
            for key, val in params.items():
                self.v[key] = np.zeros_like(val)    # 이동벡터를 W / b 의 shape만큼 생성
        
        for key in params.keys():
            self.v[key] = self.momemtum*self.v[key] - self.lr*grads[key]
            params[key] += self.v[key]
#-----------------------------------------------------------------------
# 2.3. AdaGrad class
########################################################################
class AdaGrad:
    def __init__(self, lr=0.01):
        self.lr = lr
        self.h = None

    def update(self, params, grads):
        if self.h is None:
            self.h = {}
            for key, val in params.items():
                self.h[key] = np.zeros_like(val)
        
        for key in params.keys():
            self.h[key] += grads[key] * grads[key]
            params[key] -= self.lr * grads[key] / np.sqrt(self.h[key] + 1e-7)
#-----------------------------------------------------------------------
# 2.4. Adam class
########################################################################
class Adam:
    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):
        self.lr = lr
        self.beta1 = beta1
        self.beta2 = beta2
        self.iter = 0
        self.m = None
        self.m = None

    def update(self, params, grads):
        if self.m is None:
            self.m, self.v = {}, {}
            for key, val in params.items():
                self.m[key] = np.zeros_like(val)
                self.v[key] = np.zeros_like(val)

        self.iter += 1
        lr_t = self.lr * np.sqrt(1 - self.beta2**self.iter) / (1 - self.beta1**self.iter)

        for key in params.keys():
            self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]
            self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)
            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)
#-----------------------------------------------------------------------
# 3.1. Trainer class
########################################################################
class Trainer:
    def __init__(self, network, x_train, t_train, x_test, t_test, epochs=20, mini_batch_size=100, optimizer='SGD', optimizer_param={'lr':0.01}, evaluate_sample_num_per_epoch=None, verbose=True):
        self.network = network
        self.verbose = verbose
        self.x_train = x_train
        self.t_train = t_train
        self.x_test = x_test
        self.t_test = t_test
        self.epochs = epochs
        self.batch_size = mini_batch_size
        self.evaluate_sample_num_per_epoch = evaluate_sample_num_per_epoch

        # optimizer class instance화
        optimizer_class_dict = {'sgd':SGD, 'momentum':Momentum, 'adagrad':AdaGrad, 
        'adam':Adam}
        self.optimizer = optimizer_class_dict[optimizer.lower()](**optimizer_param)
        
        self.train_size = x_train.shape[0]
        # batch size로 나눠지지 않으면 훈련이 돌아가지 않게 설계
        self.iter_per_epoch = max(self.train_size / mini_batch_size, 1) 
        self.max_iter = int(epochs * self.iter_per_epoch)
        self.current_iter = 0
        self.curren_epoch = 0

        self.train_loss_list = []
        self.train_acc_list = []
        self.test_acc_list = []

    def train_step(self):
        # data 분할
        batch_mask = np.random.choice(self.train_size, self.batch_size)
        x_batch = self.x_train[batch_mask]
        t_batch = self.t_train[batch_mask]
        # 각 가중치의 gradient 저장 / optimizer에 따른 업데이트 진행
        grads = self.network.gradient(x_batch, t_batch)
        self.optimizer.update(self.network.params, grads)
        # cross entropy loss 출력
        loss = self.network.loss(x_batch, t_batch)
        self.train_loss_list.append(loss)
        if self.verbose: print('train loss : ' + str(loss))
        # epoch 단위로 데이터 샘플 정확도 계산
        if self.current_iter % self.iter_per_epoch == 0:
            self.curren_epoch += 1
            
            x_train_sample, t_train_sample = self.x_train, self.t_train
            x_test_sample, t_test_sample = self.x_test, self.t_test
            # epoch당 샘플 수 제한하여 평가
            if not self.evaluate_sample_num_per_epoch is None:
                t = self.evaluate_sample_num_per_epoch
                x_train_sample, t_train_sample = self.x_train[:t], self.t_train[:t]
                x_test_sample, t_test_sample = self.x_test[:t], self.t_test[:t]

            train_acc = self.network.accuracy(x_train_sample, t_train_sample)
            test_acc = self.network.accuracy(x_test_sample, t_test_sample)
            self.train_acc_list.append(train_acc)
            self.test_acc_list.append(test_acc)

            if self.verbose:
                print("=== epoch : "+str(self.curren_epoch)+", train acc : "+str(train_acc)+", test acc : "+str(test_acc)+" ===")
        self.current_iter += 1

    def train(self):
        for i in tqdm(range(self.max_iter), desc='SimpleConvNet Learning'):   
            self.train_step()

        test_acc = self.network.accuracy(self.x_test, self.t_test)

        if self.verbose:
            print("========== Final Test Accuracy ===========")
            print("test acc : "+str(test_acc))
```

이를 기반으로 CNN을 구현해보겠습니다. 기존 구현한 것과 다른 부분은 상세히 주석처리 하였습니다.


```python
class SimpleConvNet:
    def __init__(self, input_dim=(1, 28, 28), conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1}, hidden_size=100, output_size=10, weight_init_std=0.01):
        filter_num = conv_param['filter_num']
        filter_size = conv_param['filter_size']
        filter_pad = conv_param['pad']
        filter_stride = conv_param['stride']
        input_size = input_dim[1]   # FH, FW
        #########################################################################################################
        # 여기서 말하는 conv size는 OH, OW를 가리키는반면, pool size는 전체 shape인 (FN * P_OH * P_OW)를 의미한다
        # pooling layer input : (N, FN, OH, OW) / P_OH = (OH - PH + 2*PP)/PS + 1 = (OH-2)/2+1 = OH/2 = OW/2 => P_OW
        # 암시적으로 pooling_pad = 2, pooling_stride = 2를 사용했음을 알 수 있다. 유의할 것
        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1 # OH, OW
        pool_output_size = int(filter_num * (conv_output_size/2) ** 2)  # FN*(OH/2)^2 = FN*P_OH*P_OW
        #########################################################################################################
        

        #########################################################################################################
        # (1. Conv) - (2. ReLU) - (3. Pooling) - (4. Affine) - (5. ReLU) - (6. Affine) - (7. Softmax)
        # init params
        self.params = {}
        # 1. conv operation : 2-dim input feature map과 2-dim filter와 matrix product를 위한 filter 값 초기화
        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size) # filter : (FN, C, FH, FW)
        self.params['b1'] = np.zeros(filter_num)
        # 2. ReLU operation이 여기서 진행되는데, 이미지 0 값만 0이 되고 나머지는 항등함수 역할을 하므로 shape은 보존된다
        # 3. Pooling operation 은 진행되면서 (N, FN, P_OH, P_OW) 상태로 출력. 
        # 4. Pooling feature map과 hidden layer 간 Affine이 W2 shape : (FN*PH*PW,hidden_size) 상태로 연산진행. batch size N은 반복문으로 연산
        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)
        self.params['b2'] = np.zeros(hidden_size)
        # 5. ReLU
        # 6. Affine
        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)
        self.params['b3'] = np.zeros(output_size)
        #########################################################################################################

        self.layers = OrderedDict()
        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'], conv_param['stride'], conv_param['pad'])
        self.layers['Relu1'] = Relu()
        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)
        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])
        self.layers['Relu2'] = Relu()
        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])
        self.last_layer = SoftmaxWithLoss()
    
    def predict(self, x):
        for layer in self.layers.values():
            x = layer.forward(x)

        return x
    
    def loss(self, x, t):
        y = self.predict(x)
        return self.last_layer.forward(y, t)

    def accuracy(self, x, t, batch_size=100):
        if t.ndim != 1: t = np.argmax(t, axis=1)
        
        acc = 0
        # 굳이 다 하면 되는걸 batch 구분지어 반복문 돌리는 이유를 모르겠네요
        for i in range(int(x.shape[0] / batch_size)):   # train_num / batch_num
            tx = x[i*batch_size:(i+1)*batch_size]       # i - i+1 번째 batch에 대한 x 값들
            tt = t[i*batch_size:(i+1)*batch_size]       # i - i+1 번째 batch에 대한 t 값들
            y = self.predict(tx)                        # i - i+1 번째 batch에 대한 y 값들
            y = np.argmax(y, axis=1)                    # row 기준 softmax idx 출력
            acc += np.sum(y == tt)                      # 같은 label인 경우만 합산
                                                        # 전체 집단에 대해 100개 단위로 참 집단 합계
        return acc / x.shape[0]                         # 전체 참에 대해 전체 값으로 나눔. 즉 정확도 계산

    def gradient(self, x, t):
        # forward / Cross Entropy Error Value 출력
        self.loss(x, t)
        # backward
        dout = 1
        dout = self.last_layer.backward(dout)
        
        layers = list(self.layers.values()) # 각 layer를 역순으로 뒤집어 모든 가중치를 list에 저장 
        layers.reverse()
        for layer in layers: # layer는 layer별 전체 가중치를 의미
            dout = layer.backward(dout)
        # (6. Conv) - (5. ReLU) - (4. Pooling) - (3. Affine) - (2. ReLU) - (1. Affine) 순으로 backward 진행
        # 각 dout 값이 layer backward 함수에 전달되어 backpropagation이 차례차례 진행되며 . 이후 Class 내부 인자로 저장된 dW, db 등이 grads에 저장
        # 해당 값이 곧 손실함수에 미치는 영향력이기에 이를 줄이기 위한 학습이 optimization에 의해 이루어지게 됩니다.
        grads = {}
        grads['W1'] = self.layers['Conv1'].dW
        grads['b1'] = self.layers['Conv1'].db
        grads['W2'] = self.layers['Affine1'].dW
        grads['b2'] = self.layers['Affine1'].db
        grads['W3'] = self.layers['Affine2'].dW
        grads['b3'] = self.layers['Affine2'].db

        return grads
    
    #########################################################################################################
    # 훈련이 끝나고 fitting된 ConvNet을 추론 단계에서 사용하기 위해 그 값을 저장하고 불러오는 함수들
    def save_params(self, file_name="params.pkl"):
        params = {}
        for key, val in self.params.items():
            params[key] = val
        with open(file_name, 'wb') as f:
            pickle.dump(params, f)

    def load_params(self, file_name="params.pkl"):
        with open(file_name, 'rb') as f:
            params = pickle.load(f)
        for key, val in params.items():
            self.params[key] = val

        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):
            self.layers[key].W = self.params['W' + str(i+1)]
            self.layers[key].b = self.params['b' + str(i+1)]
    #########################################################################################################
```

위에 구현한 SimpleConvNet 신경망은

1. ConvNet
    * filter : (30, 5, 5)
    * stride : 1
    * padding : 0
2. ReLU
3. Pooling
    * pooling window : (2, 2)
    * stride : 2
    * padding : 0
4. Affine
5. ReLU
6. Affine
7. Softmax

로 구성되어 있습니다.

이제 MNIST Dataset으로 훈련을 진행하겠습니다.


```python
# 1. Load Dataset ################################################################
(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)
max_epochs = 20
#---------------------------------------------------------------------------------

# 2. Setting and Learning ########################################################
network = SimpleConvNet(input_dim=(1,28,28), conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1}, hidden_size=100, output_size=10, weight_init_std=0.01)
                        
trainer = Trainer(network, x_train, t_train, x_test, t_test, epochs=max_epochs, mini_batch_size=100, optimizer='Adam', optimizer_param={'lr': 0.001}, evaluate_sample_num_per_epoch=1000, verbose=False)
trainer.train()
#---------------------------------------------------------------------------------

# 3. Trained Model Save ##########################################################
network.save_params("SimpleConvNet.pkl")
print("Saved Network Parameters!")
#---------------------------------------------------------------------------------
```

    SimpleConvNet Learning: 100%|██████████| 12000/12000 [53:38<00:00,  3.73it/s] 


    Saved Network Parameters!



```python
plt.figure(figsize=(8, 6))
plt.plot(trainer.train_acc_list,label='train')
plt.plot(trainer.test_acc_list,label='test')
plt.title('SimpleConvNet with MNIST')
plt.xlabel('epochs'), plt.ylabel('accuracy')
plt.xlim(0,20), plt.ylim(0,1)
plt.gca().set_xticklabels(['{:0.0f}'.format(x) for x in plt.gca().get_xticks()])
plt.gca().set_yticklabels(['{:0.0%}'.format(x) for x in plt.gca().get_yticks()])
plt.legend(loc='lower right', fontsize=15)
plt.show()
```

    /var/folders/b9/mp1fh7ds7wz6829fc1klmjqr0000gn/T/ipykernel_4403/1494896466.py:7: UserWarning: FixedFormatter should only be used together with FixedLocator
      plt.gca().set_xticklabels(['{:0.0f}'.format(x) for x in plt.gca().get_xticks()])
    /var/folders/b9/mp1fh7ds7wz6829fc1klmjqr0000gn/T/ipykernel_4403/1494896466.py:8: UserWarning: FixedFormatter should only be used together with FixedLocator
      plt.gca().set_yticklabels(['{:0.0%}'.format(x) for x in plt.gca().get_yticks()])



    
![png](output_15_1.png)
    



```python
print("Final Train Acc : ", trainer.train_acc_list[-1])
print("Final Test Acc : ", trainer.test_acc_list[-1])
```

    Final Train Acc :  0.995
    Final Test Acc :  0.985


비록 기존 신경망보다 학습시간은 오래걸렸으나, 보다시피 overfitting 이슈 없이 기존 network와 비교하여 매우 우수한 성능임을 확인할 수 있습니다. 

### 6. Visualize CNN

CNN을 구현하면서 우리는 어떤 차원의 데이터가 어떤 계산에 의해 학습이 되고 있는지는 알지만, 네트워크 상에서 어떤 이미지가 전달되는지 알 수 없습니다. 이를 확인하면 알고리즘의 판단 기준을 확인할 수 있고 구현하는 입장에서 설명력을 높일 수 있습니다. 이번 절에선 관련 내용을 살펴보겠습니다.

<b>_6.1. 1번째 층의 가중치 시각화하기_</b>

CNN 첫 번쨰 층의 가중치는 filter weight에 해당합니다. 5절에 구현한 네트워크를 기반으로 보면 filter shape은 (30, 1, 5, 5) 입니다. 해당 모델이 학습되고 난 후 저장된 weight를 불러와서 이를 시각화하는 코드를 구현해보겠습니다.


```python
def filter_show(filters, nx=15, margin=3, scale=10):
    FN, C, FH, FW = filters.shape
    ny = int(np.ceil(FN / nx)) # ceil : 올림
    
    fig = plt.figure(figsize=(15,2))
    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) # 플롯 간 간격조절

    for i in range(FN):
        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])
        # cmap : color map, gray_r : white to black gradation
        # interpolation : 보간법, nearest : 축 위치간격을 조정, 가장 고해상도 
        ax.imshow(filters[i,0], cmap=plt.cm.gray_r, interpolation='nearest')
    plt.show()

# random weight
network = SimpleConvNet()
filter_show(network.params['W1'])
# learned weight
network.load_params('SimpleConvNet.pkl')
filter_show(network.params['W1'])
```


    
![png](output_18_0.png)
    



    
![png](output_18_1.png)
    


무작위 필터 값은 색 모양이 불규칙함을 확인할 수 있습니다. 하지만 학습이 진행되고 난 후의 필터의 형상은 규칙성을 띄고 있습니다. 색이 퍼지는 패턴이나 edge(색의 경계선), blob(국소적인 덩어리) 등이 이를 보여줍니다. 글씨체 인식으로 해석하자면, 글의 획이 기울어지는 다양한 부분들에 대한 필터가 반응하도록 학습이 된 것으로 확인할 수 있습니다. 그럼 학습된 필터가 어떻게 이미지를 보는지 확인하기 위해 channel을 1차원으로 줄인 일반 이미지를 가져와보겠습니다.


```python
img_15 = imread('./dataset/cactus.jpg')
img_15=img_15[:,:,0:1]
plt.imshow(img_15)
```




    <matplotlib.image.AxesImage at 0x124cb0490>




    
![png](output_20_1.png)
    


해당 이미지를 위의 학습된 필터가 각각 어떻게 보는지 확인하면 다음과 같습니다.


```python
filter_show(network.params['W1'], 15)
img = imread('./dataset/cactus.jpg')
img=img[:,:,0:1]
img = img.transpose(2,0,1)
img = img.reshape(1, *img.shape)

fig = plt.figure()

w_idx = 1
fig = plt.figure(figsize=(30,4))
fig.subplots_adjust(left=0, right=0.8, bottom=0, top=1, hspace=0.05, wspace=0.05) # 플롯 간 간격조절
for i in range(30):
    w = network.params['W1'][i]
    b = 0  # network.params['b1'][i]

    w = w.reshape(1, *w.shape)
    #b = b.reshape(1, *b.shape)
    conv_layer = Convolution(w, b) 
    out = conv_layer.forward(img)
    out = out.reshape(out.shape[2], out.shape[3])
    
    ax = fig.add_subplot(2, 15, i+1, xticks=[], yticks=[])
    ax.imshow(out, cmap=plt.cm.gray_r, interpolation='nearest')

plt.show()
```


    
![png](output_22_0.png)
    



    <Figure size 640x480 with 0 Axes>



    
![png](output_22_2.png)
    


3번째 필터의 경우는 오른쪽 대각방향에 반응한다고 할 수 있으며, 19번째 필터의 경우 blob을 잘 표현하여 꽃에 잘 반응함을 확인할 수 있습니다. 위와같이 Conv 계층에서 원시적인 정보를 추출하여 점차 뒤쪽 계층에 정보가 전달되는 것이 CNN에서 일어나는 일임을 확인하였습니다. 

<b>_6.2. 층 깊이에 따른 추출 정보 변화_</b>

CNN의 계층이 깊어질 수록 추출되는 정보는 더 추상화되는 것으로 알려져 있습니다. 아래의 AlexNet이 계층마다 보는 부분을 확인하면 다음과 같습니다.
> <span style="color:#808080">Mahendran, A., & Vedaldi, A. (2014). _Understanding deep image representations by inverting them._ 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 5188-5196.</span>


```python
img_16 = Image.open('./dataset/images/fig 7-26.png')
img_16
```




    
![png](output_25_0.png)
    



해당 신경망의 필터는 처음에 edge / blob 인지에서 시작하지만 점차 texture, parts를 거치다 결국 label에 뉴런이 반응하며 추상화되어 갑니다. 이처럼 신경망이 깊어질 수록 고급 정보를 인지할 수 있게됩니다. 

### 7. Well-Known CNN

이번절에선 이젠 딥러닝의 클래식이 되어버린 대표적인 두 신경망을 간략히 소개합니다 

<b>_7.1. LeNet_</b>



```python
img_17 = Image.open('./dataset/images/fig 7-27.png')
img_17
```




    
![png](output_28_0.png)
    



CNN의 원조라 할 수 있는 LeNet입니다. 20년전 제안된 첫 번째 CNN입니다. ReLU 대신 Sigmoid가 쓰이고 max pooling 대신 sub sampling 등이 쓰인 부분 등 소소하게 다른 점이 있지만 전체적인 아키텍처는 위의 CNN과 크게 다르지 않습니다.

<b>_7.2. AlexNet_</b>


```python
img_18 = Image.open('./dataset/images/fig 7-28.png')
img_18
```




    
![png](output_31_0.png)
    



<span style="color:#808080">_(해당 이미지는 오리지널 AlexNet과는 병렬구성 등 일부 구조가 다릅니다)_</span>

이번엔 딥러닝의 시작을 알린 AlexNet입니다. LeNet과 비교하여, 여기서 사용한 새로운 기법은 

>   1. ReLU
>   2. LRN(Local Response Normalization)을 통해 국소 정규화 계층을 이용
>   3. Dropout

등이 있습니다. 보다시피 둘의 구조에는 큰 차이는 없습니다만, 그 사이 발전한 컴퓨터 기술로 인해 대량의 병렬 연산이 가능해졌고, 이로 인해 딥러닝이 발전할 수 있게 되었습니다.

### 8. Overview

* CNN은 지금까지의 완전연결 계층 네트워크에 합성곱 계층과 풀링 계층을 새로 추가한다.
* 합성곱 계층과 풀링 계층은 im2row(이미지를 행렬로 전개하는 함수)를 이용하면 간단하고 효율적으로 구현할 수 있다.
* CNN을 시각화해보면 계층이 깊어질수록 고급 정보가 추출되는 모습을 확인할 수 있다.
* 대표적인 CNN에는 LeNet과 AlexNet이 있다.
* 딥러닝의 발전에는 빅데이터와 GPU가 크게 기여했다.
